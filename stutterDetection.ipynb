{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    " \n",
    " # load model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
    "     \n",
    "#  # load dummy dataset and read soundfiles\n",
    "# ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "# print(ds[0][\"audio\"][\"array\"])\n",
    "# print(ds[0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s ɪ m p l i p ʊ ɾ ʌ p æ ɹ ɪ ɡ ɹ æ f æ ɛ k ɚ ɪ l ɛ k ʃ ə n ʌ v z æ n d t ə n s ᵻ z ɑːɹ ɹ ᵻ l eɪ ɾ ᵻ d t uː s ɛ n t ɹ əl t ɑː p ɪ k d iː ɜː θ iː m p æ ɹ ᵻ ɡ ɹ æ f s æ k s æ k t æ z s t ɹ ʌ k tʃ ɹ oʊ t ɔːɹ z f ɔːɹ ɹ aɪ ɾ ɚ z t ə l ᵻ n aɪ z ð ɚ θ ɑː t s ɪ n d t uː ɚ n aɪ d iː p ɹ oʊ ɡ ɹ ɛ ʃ ə n æ n d ð eɪ ɔː l s oʊ h ɛ l p ɹ iː d ɚ z p ɹ ə p ɹ ɑː s ɛ s ð oʊ z θ ɑː t s æ v ɛ f ɚ t l ɪ s t i']\n"
     ]
    }
   ],
   "source": [
    "def map_to_array(batch):\n",
    "    speech_array, _ = sf.read(batch)\n",
    "    return speech_array\n",
    "data = map_to_array('audio/output.flac')  \n",
    " # tokenize\n",
    "input_values = processor(data, return_tensors=\"pt\").input_values\n",
    " \n",
    " # retrieve logits\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    " \n",
    " # take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)\n",
    " # => should give ['m ɪ s t ɚ k w ɪ l t ɚ ɹ ɪ z ð ɪ ɐ p ɑː s əl ʌ v ð ə m ɪ d əl k l æ s ᵻ z æ n d w iː ɑːɹ ɡ l æ d t ə w ɛ l k ə m h ɪ z ɡ ɑː s p əl']\n",
    "print(transcription)\n",
    "\n",
    "# data_s = map_to_array('audio/test2monostutter.flac')  \n",
    "#  # tokenize\n",
    "# input_values = processor(data_s, return_tensors=\"pt\").input_values\n",
    " \n",
    "#  # retrieve logits\n",
    "# with torch.no_grad():\n",
    "#     logits = model(input_values).logits\n",
    " \n",
    "#  # take argmax and decode\n",
    "# predicted_ids = torch.argmax(logits, dim=-1)\n",
    "# transcriptionStutter = processor.batch_decode(predicted_ids)\n",
    "#  # => should give ['m ɪ s t ɚ k w ɪ l t ɚ ɹ ɪ z ð ɪ ɐ p ɑː s əl ʌ v ð ə m ɪ d əl k l æ s ᵻ z æ n d w iː ɑːɹ ɡ l æ d t ə w ɛ l k ə m h ɪ z ɡ ɑː s p əl']\n",
    "# print(transcriptionStutter)\n",
    "transcriptionStutter = [\"sɪmpli pʊt, ə ˈpɛrəˌgræf ɪz ə kəˈlɛkʃən əv ˈsɛntənsɪz ɔl rɪˈleɪtɪd tɪ ə ˈsɛntrəl ˈtɑpɪk, aɪˈdiə, ər θim. ˈpɛrəˌgræfs ækt ɛz ˈstrəkʧərəl tulz fər ˈraɪtərz tɪ ˈɔrgəˌnaɪz ðɛr θɔts ˈɪntu ən aɪˈdil prəˈgrɛʃən, ənd ðeɪ ˈɔlsoʊ hɛlp ˈridərz ˈprɔˌsɛs ðoʊz θɔts ˈɛfərtləsli\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sɪmpli pʊt, ə ˈpɛrəˌgræf ɪz ə kəˈlɛkʃən əv ˈsɛntənsɪz ɔl rɪˈleɪtɪd tɪ ə ˈsɛntrəl ˈtɑpɪk, aɪˈdiə, ər θim. ˈpɛrəˌgræfs ækt ɛz ˈstrəkʧərəl tulz fər ˈraɪtərz tɪ ˈɔrgəˌnaɪz ðɛr θɔts ˈɪntu ən aɪˈdil prəˈgrɛʃən, ənd ðeɪ ˈɔlsoʊ hɛlp ˈridərz ˈprɔˌsɛs ðoʊz θɔts ˈɛfərtləsli']\n",
      "1.0\n",
      "0.22905027932960895\n",
      "1.3636363636363635\n",
      "1.0\n",
      "0.8888888888888888\n",
      "1.5\n",
      "1.0\n",
      "0.6\n",
      "0.0\n",
      "0.0\n",
      "0.2727272727272727\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.5714285714285714\n",
      "0.8333333333333334\n",
      "0.0\n",
      "0.6666666666666666\n",
      "4.166666666666667\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.7142857142857143\n",
      "1.0714285714285714\n",
      "0.0\n",
      "0.2\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.5\n",
      "2.0\n",
      "1.3333333333333333\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(transcriptionStutter)\n",
    "searched = set()\n",
    "stutterPhonemes = []\n",
    "for phoneme in transcription[0]:\n",
    "    if phoneme not in searched:\n",
    "        searched.add(phoneme)\n",
    "        og = transcription[0].count(phoneme)\n",
    "        vc = transcriptionStutter[0].count(phoneme)\n",
    "        score = float(vc) / float(og)\n",
    "        print(score)\n",
    "        if score > 2:\n",
    "            stutterPhonemes.append(phoneme)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ə']\n"
     ]
    }
   ],
   "source": [
    "print(stutterPhonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h ʌ l oʊ m aɪ n eɪ m ɪ z h ɛ n ɹ i']\n",
      "['x', 'a', 'ɑ', 'h', 'ɑ', 'x', 'x', 'ɑ', 'l', 'oː'] ['h', 'ʌ', 'l', 'oʊ']\n",
      "h x\n",
      "ʌ a\n",
      "l ɑ\n",
      "oʊ h\n",
      "  ɑ\n",
      "  x\n",
      "  x\n",
      "  ɑ\n",
      "  l\n",
      "  oː\n"
     ]
    }
   ],
   "source": [
    "# print(transcription)\n",
    "# transcription = transcription[0].split(\" \")\n",
    "# transcriptionStutter = transcriptionStutter[0].split(\" \")\n",
    "\n",
    "# hello = transcription[:4]\n",
    "# helloStutter = transcriptionStutter[:10]\n",
    "# print(helloStutter, hello)\n",
    "# for i in range(max(len(hello), len(helloStutter))):\n",
    "#     if i >= len(hello):\n",
    "#         print(\" \", helloStutter[i])\n",
    "#     elif i >= len(helloStutter):\n",
    "#         print(hello[i], ' ')\n",
    "#     else:\n",
    "#         print(hello[i], helloStutter[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'oʊ']\n"
     ]
    }
   ],
   "source": [
    "from torch import le\n",
    "\n",
    "\n",
    "col = {'x':'h', 'h':'h'}\n",
    "vowel = {'i', 'e', }\n",
    "testa = ['h', 'ʌ', 'l', 'oʊ']\n",
    "testb = ['h', 'h', 'h', 'ʌ', 'l', 'oʊ', 'oʊ']\n",
    "indexStutter = 0\n",
    "stutterPho = []\n",
    "for index, letter in enumerate(testa):\n",
    "    if indexStutter >= len(testb):\n",
    "        break\n",
    "    if testb[indexStutter] != letter:\n",
    "        stutterPho.append(letter)\n",
    "        # if testb[indexStutter + 1] == letter:\n",
    "    else:\n",
    "        indexStutter += 1\n",
    "        if indexStutter >= len(testb):\n",
    "            break\n",
    "        if index == len(testa) - 1:\n",
    "            if testb[indexStutter] == letter:\n",
    "                stutterPho.append(letter)\n",
    "                break\n",
    "        elif testb[indexStutter] == letter and (testa[index + 1] != letter):\n",
    "            stutterPho.append(letter)\n",
    "            indexStutter += 1\n",
    "            if indexStutter >= len(testb):\n",
    "                break\n",
    "            while testb[indexStutter] == letter:\n",
    "                indexStutter += 1\n",
    "print(stutterPho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hackmit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac119f78188e5cf5aa1c6f75b4e881a1ea9af5cd76ea01b55255750fd318d524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
